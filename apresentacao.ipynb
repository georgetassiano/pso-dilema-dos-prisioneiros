{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSO para Dilema dos Prisioneiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importações necessárias para o projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto é totalmente customizável para a execução de qualquer função de otimização. Bastando apenas criar a função de otimização extendendo da classe FunctionOptimizationBase em models/functions_optimization/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pso.pso_algorithm import PSOAlgorithm\n",
    "from models.pso.swarm import Swarm\n",
    "from models.functions_optimization.function_optimization_dp_individual_base import FunctionOptimizationDPIndividualBase as DPIndividual\n",
    "from models.functions_optimization.function_optimization_dp_coletivo_base import FunctionOptimizationDPColetivoBase as DPColetivo\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros de execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_length = 50  # quantidade de particulas\n",
    "global_comparison_length_10 = round(particles_length * 0.1)  # quantidade de particulas para comparar (10%)\n",
    "global_comparison_length_30 = round(particles_length * 0.3)  # quantidade de particulas para comprar (30%)\n",
    "lower_limit = 0.0  # limite inferior da função\n",
    "upper_limit = 1.0  # limite superior da função\n",
    "max_interation = 1000  # máximo de interações\n",
    "max_execution = 5  # máximo de execuções \n",
    "\n",
    "c = 3  # quantidade de posições cooperativas para aplicação de 1 bonus\n",
    "bonus = -0.5  # bonus a ser dado por cada bonus a ser dado\n",
    "inertial_ini = 1.2  # valor da variável de inércia inicial\n",
    "inertial_final = 0.8  # valor da variável de inércia final\n",
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando os parâmetros da constante de social information e cognitive information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI e SI possuem o mesmo valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "\n",
    "functions_optimization = []\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit), 'Coletivo'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Coletivo 10'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Coletivo 30'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit), 'Individual'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Individual 10'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Individual 30'])\n",
    "\n",
    "for e in range(len(functions_optimization)):\n",
    "    \n",
    "    algorithm = PSOAlgorithm(functions_optimization[e][0], max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, functions_optimization[e][0], inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0] \n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento {functions_optimization[e][1]}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CI possui o dobro do valor de SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Valor\n",
       "ci    2.0\n",
       "si    1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = 2.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "\n",
    "functions_optimization = []\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit), 'Coletivo'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Coletivo 10'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Coletivo 30'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit), 'Individual'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Individual 10'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Individual 30'])\n",
    "\n",
    "for e in range(len(functions_optimization)):\n",
    "    \n",
    "    algorithm = PSOAlgorithm(functions_optimization[e][0], max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, functions_optimization[e][0], inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0] \n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento {functions_optimization[e][1]}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI possui o dobro de valor do CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Valor\n",
       "ci    1.0\n",
       "si    2.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 2.0  # valor da constante de relevância da informações social\n",
    "\n",
    "functions_optimization = []\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit), 'Coletivo'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Coletivo 10'])\n",
    "functions_optimization.append([DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Coletivo 30'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit), 'Individual'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10), 'Individual 10'])\n",
    "functions_optimization.append([DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30), 'Individual 30'])\n",
    "\n",
    "for e in range(len(functions_optimization)):\n",
    "    \n",
    "    algorithm = PSOAlgorithm(functions_optimization[e][0], max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, functions_optimization[e][0], inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0] \n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento {functions_optimization[e][1]}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a influência do bonus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPIndividual(lower_limit, upper_limit, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Individual com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual 10 com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Individual 10 com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### individual 30 com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Valor\n",
       "bonus   -1.5\n",
       "c        1.0\n",
       "ci       1.0\n",
       "si       1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPIndividual(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Individual 30 com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coletivo com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Valor\n",
       "bonus   -2.0\n",
       "c        1.0\n",
       "ci       1.0\n",
       "si       1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPColetivo(lower_limit, upper_limit, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Coletivo com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coletivo 10 com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>si</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Valor\n",
       "bonus   -3.0\n",
       "c        1.0\n",
       "ci       1.0\n",
       "si       1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_10, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Coletivo 10 com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coletivo 30 com bonus variando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = 1.0  # valor da constante da relevância da informação pessoal\n",
    "si = 1.0  # valor da constante de relevância da informações social\n",
    "c = 1 # tamanho da cadeia de cooperação\n",
    "\n",
    "for e in range(6):\n",
    "    bonus = np.float_(-e)  # bonus a ser dado por cada cadeia de cooperação\n",
    "    \n",
    "    function_optimization = DPColetivo(lower_limit, upper_limit, global_comparison_length=global_comparison_length_30, bonus=bonus, c=c)\n",
    "    algorithm = PSOAlgorithm(function_optimization, max_interation, max_execution)\n",
    "    algorithm.exec_algorithm(particles_length, function_optimization, inertial_ini, inertial_final, ci, si)\n",
    "    result = algorithm.get_result()\n",
    "\n",
    "    plotarBest = np.zeros([np.size(result, 0)])\n",
    "    plotarAvarege = np.zeros([np.size(result, 0)])\n",
    "    plotarLowest = np.zeros([np.size(result, 0)])\n",
    "\n",
    "    plotarBar = [result[0][1][0], result[500][1][0], result[-1][1][0]]\n",
    "\n",
    "    for i in range(np.size(result, 0)):\n",
    "        plotarBest[i] = result[i][0][0]\n",
    "        plotarAvarege[i] = result[i][1][0]\n",
    "        plotarLowest[i] = result[i][2][0]\n",
    "\n",
    "    plt.figure(e)\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(f'Pensamento Coletivo 30 com bonus={bonus} e c={c}')\n",
    "    plt.plot(plotarBest, 'r-', label='melhor') \n",
    "    plt.plot(plotarAvarege, 'b-', label='média')\n",
    "    plt.plot(plotarLowest, 'g-', label='pior')\n",
    "    plt.xlabel('nº iteração')\n",
    "    plt.ylabel('nº cooperações')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(np.arange(3), plotarBar)\n",
    "    plt.xticks(np.arange(3), ('inicial', 'meio', 'fim'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
